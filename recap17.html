---
layout: page
title: Lecture 17 Recap - Graphical Models
mathjax: true
weight: 0
---

<section class="main-container text">
    <div class="main">

      <h4>Date: March 30, 2021 (<a href="https://docs.google.com/forms/d/e/1FAIpQLSdPFqXZpt1gdKSsuQ5fy91ddIUqsa9mxsxMZ-9G9eKrSqLruw/viewform" target="_blank">Concept Check</a>, <a href="https://docs.google.com/forms/d/e/1FAIpQLSdPFqXZpt1gdKSsuQ5fy91ddIUqsa9mxsxMZ-9G9eKrSqLruw/viewanalytics" target="_blank">Class Responses</a>, <a href="{{ site.baseurl }}/ccsolutions" target="_blank">Solutions</a>)</h4>
      <h4>Relevant Textbook Sections: 8</h4>
      <h4>Cube: Probabilistic</h4>

      <br>

      <h4><a href="https://harvard.zoom.us/rec/play/x76cCsHAI0vLpUhd6EH0A9scy3D-jd0amxopwznzvfKaLI6WSoXUqHvSTOnqb0BvkfubDttVWrvPZBYs.XkwOMe2Ov7jvXsSU">Lecture Video</a></h4>
      <h4><a href="files/lecture17_ipad.pdf" target="_blank">iPad Notes</a></h4>
      <!-- <h4><a href="files/lecture15_slides.pdf" target="_blank">Slides</a></h4> -->

      <h3>Lecture 17 Summary</h3>

      <ul>
        <li><a href="#recap17_1">Intro: Motivation Behind Graphical Models</a></li>
        <li><a href="#recap17_2">Graphical Models</a></li>
        <li><a href="#recap17_3">Bayesian Networks</a></li>
        <li><a href="#recap17_4">Uniqueness and Parameters</a></li>
        <li><a href="#recap17_5">Beyond Bayes Nets</a></li>
      </ul>

      <h2 id="recap17_1">Intro: Motivation Behind Graphical Models</h2>

      Today we're going to be moving beyond the cube.  Just as we moved into more flexible parametric relationships with neural networks, we can think of graphical models as a way of describing more complex relationships between variables than those we've seen so far in supervised and unsupervised learning.<br><br>

      <!-- <h4>Example: Predicting Drug Interactions</h4>

      One particularly relevant example of such a complex relationship is predicting drug interactions.  Say you have a collection of drugs. For some drugs, you may know what molecules they target, but for others, you do not.  These relationships are indicated by the lines from drugs to targets.  You may also have additional information about the relationship between the drugs' chemical forms, for example, that two drugs may be chemically similar.  These relationships are indicated by the lines between drugs.<br>

      <div id="images">
          <a>
              <img src="{{ site.baseurl }}/images/recap17_1.png" style="width:80%"  alt="drug interactions"></img>
              <div class="caption">Drug interaction graphical model.</div>
          </a>
      </div>

      Given these known relationships between drugs and targets, you wish to be able to predict whether other two drugs may hit the same target.  You also may be interested in whether a particular drug can be repurposed to hit a new target.  We cannot answer this problem using simple multiclass classification - instead we wish to model all of specific relationships between each drug and each target.<br><br>

      <h4>Example: Information Retrieval</h4>

      Another example is information retrieval.  A particularly famous example of using graphical models to represent relationships would be <a href="https://www.cs.princeton.edu/~chazelle/courses/BIB/pagerank.htm">Google's Pagerank algorithm</a>; more generally, graphical models can model all relationships between elements in a knowledge graph.<br> -->

      <h2 id="recap17_2">Graphical Models</h2>

      Graphical models provide a structured representation of the probabilistic relationships in a problem. Graphical models help us visualize and communicate about models.<br><br>

      We've already been informally drawing graphical models for a long time! In supervised learning, we considered cases where a hidden label y generated x’s (generative), or a hidden label x generated y’s (discriminative). We diagrammed the generative scenario with an arrow pointing from y to x, and the discriminative scenario with an arrow from x to y.<br><br>

      <div id="images">
          <a>
              <img src="{{ site.baseurl }}/images/recap17_1.png" style="width:70%"  alt="gms"></img>
              <div class="caption">Figure 1</div>
          </a>
      </div>

      More recently, we’ve seen scenarios with more complicated diagrams. For mixture models, which are depicted in Figure 1 left, a hidden z generated x’s. We draw this in a plate to denote that we have a whole set of N z’s generated this way. The z’s and x’s were also affected by our parameters $\pi, \mu, \Sigma$.<br><br>

      We also saw topic models, which lead to the even more complicated diagram in Figure 1 right. These diagrams help encode the structure of the data, including relationships between variables. <br><br>
      
      <!-- The first graph on the far left represents a generative process where labels $y$ are used to generate features $x$.<br><br>

      The second graph from the left represents a probabilistic process where labels $y$ are assigned a probability given features $x$.<br><br> -->

      <!-- The third and fourth graphs from the left are used to represent simplified and expanded versions of <a href="https://harvard-ml-courses.github.io/cs181-web/recap16">LDA</a>.<br><br> -->

    
    
    
    
    
    
      <h4>Notation and Rules</h4>

      The notation we use in our graphical models is as follows.<br><br>

      <ol>
        <li> Random variables are represented by an open circle.  If we observe a random variable of a given model, then we shade it in. Otherwise, it's left open.</li>
        <li> Deterministic parameters are represented by a tight, small dot.</li>
        <li> Arrows indicate the probabilistic dependence relationship between different random variables and parameters.  An arrow from $X$ to $Y$ means that $Y$ depends on $X$.</li>
        <li> Plates, or boxes, indicate repeated sets of variables.  Often there will be a number in one of the corners indicating how many times that variable is repeated.  For example, if you have a training dataset of $N$ random variables $\{x_i, y_i\}_{i = 1}^{N}$ drawn from $X, Y$, you can draw a plate around $X$ and $Y$ in your model with an $N$ in the corner.</li>
      </ol><br>







<!-- 

      <h4>Dependency and Factoring</h4>

      Rule 3 suggests that we can examine a sequence of arrows in a graphical model as a chain of dependencies of the random variables they connect.  From examining the dependencies in graphical models, we can learn how to factor the joint probability distribution over all random variables in the graphical model.<br>

      Let's bring back the picture of the graphical models from above:<br>

      <div id="images">
          <a>
              <img src="{{ site.baseurl }}/images/recap17_5.png" style="width:70%"  alt="gms"></img>
              <div class="caption">Figure 1</div>
          </a>
      </div>

      Let's first examine the first graphical model from the left.  For this model, the joint probability distribution over all variables is:

      $$p(X, Y)$$

      Which, using the dependency structure given in the graphical model, we can factor into

      $$= p(Y) p(X | Y)$$

      In contrast, for the graphical model that is second from the left, we can factor the joint distribution into

      $$p(X, Y) = p(X) p(Y | X)$$

      Similarly, for the simple LDA model (third from the left), we can write the joint distribution as

      $$p(\pi, x, \theta, \alpha) = p(\alpha) p(\theta) p(\pi | \alpha) p(x | \theta, \pi)$$

      This factorization follows intuitively from looking at the graph:  because there are arrows from $\theta$ and $\pi$ to $x$, then $x$'s distribution must be conditioned on (or dependent on) $\theta$ and $\pi$.<br><br>

      For the expanded LDA model (fourth from the left), we can write the joint distribution as

      $$p(\alpha, \theta, \pi, z, w, x) = p(\theta) p(\alpha) p(\pi | \alpha) p(z | \pi) p(w | z, \theta) p( x | w)$$

      <br>

      A key point is that while graphical models can tell us important information about the joint factorization of all of the random variables, graphical models do not give us the form of the distribution.  Graphical models communicate dependencies between random variables, but do not indicate the distributions of the random variables themselves.  For example, from observing the graphical model that is the first from the left, can we determine if $p(X, Y)$ is distributed normally?  What is its mean and variance?  Graphical models cannot capture this kind of information.<br> -->





      <h2 id="recap17_3">Bayesian Networks</h2>

      A Bayesian Network is a special kind of graphical model. Bayesian Networks (Bayes Nets) are DAGs (directed acyclic graphs) where nodes represent random variables, and directed arrows represent dependency relationships between random variables. In a DAG, nodes have directed arrows between them and there are no cycles (directed paths you can follow in a loop). In DAGS, we will be able to simplify joint probabilities nicely.<br><br>

      <div id="images">
          <a>
              <img src="{{ site.baseurl }}/images/recap17_2.png" style="width:70%"  alt="bayes1"></img>
              <div class="caption">Figure 2</div>
          </a>
      </div>
      
      For example, the joint distribution of random variables $(A, B, C, D, E)$ can be inferred from the dependency relationships specified by the Bayes Net in Figure 2 above:

    \begin{align*}
    p(A,B,C,D,E) &= p(A)p(B|A)p(C|B,A)p(D|A,B,C)p(E|A,B,C,D)
    \\ &= p(A)p(B|A)p(C|A)p(D|C,A)p(E|D)
    \end{align*}

      <!-- $$p(A, B, C, D, E) = p(A) p(D | A) p(B | A) p(C | A, B) p(E | C)$$

      Notice that even without any knowledge of the dependency relationships between the variables, we could always factor the joint distribution as

      $$p(A, B, C, D, E) = p(A) p(B | A) p(C | B, A) p(D | C, B, A) p( E | D, C, B, A)$$ -->

      Where the last line comes from looking at which variables depend on which other variables in the diagram. For example, C and B depend only on A, D depends on C and A, and E depends only on D. Then $ p( E | D, C, B, A)$ can be simplified to $p(E | D)$.<br><br>

      Why are Bayes Nets and the structure they provide useful?<br><br>

      <ol>
        <li> For inference: Knowing which variables are independent helps us determine when we can use block coordinate ascent to infer their values.
            
            <!-- For inference:  if our goal is to fit some of the variables, given others, then we can do block coordinate ascent or alternating optimization schemes.<br><br> -->
<!-- 
            For example in Figure 2, given $C$, $E$ becomes independent of all other random variables in the network.<br><br>

            Therefore a possible inference scheme is to first guess that $C = c$.  Given this guess of $C$, now we can update our guesses of $A, B, D$ and $E$.  Then, given these guesses for $A$, $B$, $D$, and $E$, we now can update our guess of $C$.  We can continue ``swapping'' between updating our guesses of these two groups of variables.<br><br> -->
        </li>
        <li> For learning:  Bayes Nets allow us to learn "smaller" distributions, or distributions with fewer parameters.<br><br>

            For example, before the joint distribution for the network in Figure 2 is simplified, $p(E | D, C, B, A)$ is dependent on $\{A, B, C, D\}$.  If each of $\{A, B, C, D\}$ is binary, then there are 16 different "settings" of $p(E | D, C, B, A)$; for example $p(E | D = 0, C = 0, B= 0, A = 0)$, $P(E | D = 1, C = 0, B= 0, A = 0)$, etc.  As such, we require 16 different "parameters", or terms $p(E | D, C, B, A)$, to fully specify the distribution.<br><br>

            However, after simplifying this term to $p(E | D)$, we only need to learn $p(E | D = 0)$ and $p(E | D = 1)$ to fully specify the distribution $p(E | D)$.<br><br>
        </li>
      </ol>

      <h4>Intuition for D-separation</h4>

      <!-- First we'll informally explore how conditioning on random variables may affect dependency, using this Bayes Net as an example: -->

      <div id="images">
          <a>
              <img src="{{ site.baseurl }}/images/recap17_3.png" style="width:60%"  alt="bayes2"></img>
              <div class="caption">Figure 3</div>
          </a>
      </div>

      We will begin by defining the principle of local independence: <b>every node is conditionally independent of its non-descendants, given only its parents.</b><br><br>

      Imagine that students have skill level S and diligence D, which affect how they do in a course as shown in Figure 3. Observe that we’re using our prior beliefs about how these variables interact to bring structure to the data. <br><br>
     
      Given $G$ and $U$, $E \perp H, S, D$ (or $E$ is conditionally independent ($\perp$) of $H$, $S$, and $D$) by local independence.<br><br>

      Q: Given $S$, are $G$ and $U$ independent?<br>
      A: Yes: local independence says that $G$ and $U$, which are non-descendants, are independent given their parent $S$. In the graph, this means that G and U are related only through S, their parent. So given the parent, they are independent.<br><br>
      
      Q: Given $E$, are $G$ and $U$ independent?<br>
      A: No. We cannot apply the principle of local independence because $E$ is not a parent of $G$ or $U$.<br><br>

      Intuitively, if you know that someone did well on their exam, and you find out that they really understood the material,  then you may have less idea of if they are a good test taker. Knowing that they really understood the material already “explains" their high performance on the exam.  Therefore conditioned on observing the student's exam score, understanding the material and being a good test taker are dependent variables.  This general phenomenon is called the explaining-away effect.<br><br>

      <h4>The D-separation Rules</h4>

      When discussing D-separation, we use the term "information flow" to describe dependencies between variables.  If there is information flowing from $A$ to $B$, then $A$ and $B$ are conditionally dependent given the observed random variables.  In contrast, if $A$ and $B$ are "blocked", then $A$ and $B$ are conditionally independent given the observed random variables.<br><br>

      <b>Two variables $A$ and $B$ are D-separated, or independent, if every undirected path from $A$ to $B$ is “blocked".</b><br><br>

      There are several ways a path can be "blocked":<br>

      <div id="images">
          <a>
              <img src="{{ site.baseurl }}/images/recap17_4.png" style="width:80%"  alt="bayes3"></img>
              <div class="caption">Figure 4</div>
          </a>
      </div>

      <u>Case 1 and 2:</u>

      In Case 1, if we have observed $C$, then $B$, which is a descendant, will be independent of $A$ (by local independence). Case 2 is symmetric. <br><br>
      
      <u>Case 3:</u>

      In Case 3, $C$ is the parent of both $A$ and $B$.  Because $A$ and $B$ are not descendents of each other, $A$ and $B$'s conditional independence follows by local independence.<br><br>

      <!-- Another contextualized example is: say $C$ represents the bias of a coin.  $A$ and $B$ represent two independent flips of the coin.  When $C$ is unobserved, then $A$ and $B$ are dependent, as observing the result of flip $A$ may give information about the bias $C$ of the coin, which also gives information about $B$.  But once $C$, the bias of the coin, is observed, then $A$ is now independent of $B$.<br><br> -->

      <u>Case 4:</u>

      In Case 4, not observing C blocks the path.  When C is observed, it induces a correlation, or dependency between $A$ and $B$.<br>

      <!-- An example of this is $C$ being the XOR of $A$ and $B$.  When $C$ is unobserved, $A$ and $B$ are uncorrelated.  But once $C$ is observed, $B$ can be calculated from observing $A$ and $C$.<br><br> -->

      Section 8.2.5 of the textbook discusses each of these D-separation rules more in-depth, we strongly recommend that you read it as a supplement to this lecture!<br><br>

      <h2 id="recap17_4">Uniqueness and Parameters</h2>


      <h4>Uniqueness</h4>

      Under a causal interpretation, A causes B and we cannot say that B causes A. <br><br>

      But under a statistical interpetation, instead of thinking about causal relationships, we think about how knowing the value of A can inform us about what the distribution of B is. Similarly, knowing B informs us about the distribution of A.<br><br>

      Given any two random variables $(A, B)$, we can write the joint distribution $p(A, B)$ two ways. Each equation has an associated "ordering", which is the direction of the arrow.

      $$A \longrightarrow B: p(A, B) = p(A) p(B | A)$$
      $$B \longrightarrow A: p(A, B) = p(B) p(A | B)$$

      A statistical interpretation allows for multiple orderings, but one ordering may require the fewest parameters and contain the most independences.<br><br>


      <!-- <div id="images">
          <a>
              <img src="{{ site.baseurl }}/images/recap17_10.png" style="width:80%"  alt="bayes4"></img>
              <div class="caption">Figure 5</div>
          </a>
      </div> -->
<!-- 
      Q: When factoring our Bayes Nets (or, more broadly, when factoring joint distributions in this course), which way should we choose, given that both of the above equations are mathematically correct?<br><br>

      A: If we are given some causal knowledge, for example, if we know that $A$ causes $B$, then we should factor the joint distribution using $p(A, B) = p(A) p(B | A)$.  We cannot ``flip the ordering'' under this causal assumption.  Therefore in this case, there is 1 unique factorization that is consistent with our causal knowledge.<br><br>

      But otherwise, you can choose any factorization you'd like, given that the factorization is mathematically correct.  However, some choices of the ordering are easier to work with than others.<br><br> -->

      <h4>Example: Ordering affects the number of necessary parameters</h4>

      Example: Recall our network from Figure 3, here written using simplified variable names:

      <div id="images">
          <a>
              <img src="{{ site.baseurl }}/images/recap17_5.png" style="width:60%"  alt="bayes5"></img>
              <div class="caption">Figure 5</div>
          </a>
      </div>

      Suppose all variables are binary.  How many parameters does this network need?  Or, otherwise stated, how many different values do we need to know to be able to calculate the joint distribution $p(S = s, D = d, G = g, U = u, E = e, H = h)$ for all possible values $s, d, g, u, e, h \in \{0, 1\}$?<br><br>

      First, notice that $p(S)$ can be fully specified by $1$ parameter, as $p(S = 0) = 1- p(S = 1)$.<br><br>

      Similarly, $p(G | S)$ can be fully specified by 2 parameters $p(G = 1 | S = 0)$ and $p(G = 1 | S = 1)$, as $p(G = 0 | S = 0) = 1 - p(G = 1 | S = 0)$, etc. Basically, we need one parameter for each case where S came up 1 or 0. If S is 1, what’s the probability that G is 1? And if S is 0, what’s the probability that G is 1? <br><br>

      <!-- It is a good exercise to reason about the number of parameters required for each term in the joint distribution for our Bayes Net.  In Figure 6, we've written the number of necessary parameters for each variable's conditional distribution term next to the variable.  Therefore the network needs -->

      $p(U | S,D)$ will need 4 parameters for the 4 cases (S=0,D=0), (S=0,D=1), (S=1,D=0), (S=1, D=1) because it has 2 parents which could each take one of 2 possible values. Going on with this reasoning, E, G, and U would need 4 parameters each, and H would need 2 parameters. Then the whole network needs <br><br>

      $$1 + 2 + 4 + 1 + 4 + 2 = 14$$

      total parameters.

      <h4>Re-ordering the Network</h4>

      We can change the topology (ordering) of the net, while preserving the same dependency relationships between variables.  For example, the network in Figure 7 is the one from Figure 6 with a re-ordered topology, preserving the relationships from Figure 6:

      <div id="images">
          <a>
              <img src="{{ site.baseurl }}/images/recap17_6.png" style="width:60%"  alt="bayes6"></img>
              <div class="caption">Figure 6</div>
          </a>
      </div>

      Say that we wish to place $E$ at the top of the network.  Now, we consider $H$.  Can $H$ be chosen independently of $E$ in the original network?  No, because its parent $U$ (in the original network) has not been observed, so there is an unblocked path $(E, U, H)$ between them.  Therefore we need an arrow from $E$ to $H$.<br><br>

      Next, we add $U$ to the new network.  $U$ is not independent of $E$ or $H$, so we need to draw arrows from $E$ and $H$ to $U$.<br><br>

      We add $S$ to the new network.  $S$ depends on $U$ and $E$ because we have not observed $G$ yet.  Because $U$ has been observed, blocking all paths from $S$ to $H$, we do not draw an arrow from $H$ to $S$.<br><br>

      We add $G$ to the network.  $G$ depends on $E$ and $S$, so we draw arrows from $E$ and $S$ to $G$.<br><br>

      Finally we add $D$, which depends on $U$ and $S$.<br><br>

      This new network respects all the dependencies of the original network.  Note that the new network contains more dependencies (or arrows) than our original network.<br><br>

      Our new network in Figure 7 has 19 required parameters.  It requires more parameters than our original network.<br><br>


      <!-- <div id="images">
          <a>
              <img src="{{ site.baseurl }}/images/recap17_7.png" style="width:70%"  alt="bayes7"></img>
              <div class="caption">Figure 8</div>
          </a>
      </div> -->

      <!-- This network corresponds to factoring the joint distribution as

      $$p(E, S, U, H, G, D) = p(E) p(S | E) p(U | E, S) ...$$

      While such an ordering is correct, it is not parsimonious.  Our hope is to find a variable ordering which respects all necessary dependency relationships, while using as few "arrows" or having as few dependencies as possible.  Generally, adding another arrow or dependency to a Bayes Net will increase the number of parameters required to specify the full joint distribution.  As such, networks that have fewer arrows but still preserve the original dependency relationships will require fewer parameters to specify their joint distributions.<br><br>

      This fully-connected graph requires $1 + 2 + 4 + 8 + 16 + 32 = 63$ parameters.<br><br> -->

      <!-- Student question:  What does the direction of the arrows imply?  Do the arrows inform us of how the data is generated?  In the top image, for example, $G$ and $U$ points to $E$.  In the bottom image, $E$ points to $H$ and $U$.<br><br>

      Answer:  You are correct in that it is possible to draw two Bayes Nets that preserve the dependency relationships between variables, but, because of their differing structure, tell a different "story" about each random variable in the network.  This relates to the "Uniqueness and Parameters" discussion above.  Typically, you wish to draw a graphical model that corresponds with your knowledge and your assumptions about a causal or data-generating process.<br><br>

      To contextualize our examples, in Figure 6, $G$ and $U$ point to $E$.  The joint distribution of this Bayes Net can be factored as

      $$p(S) p(D) p(G | S) p(U | S, D) p(E | G, D) p (H | U)$$

      This would represent a causal setting where we assume that being a good test taker and understanding material causes one's exam score.<br>

      In contrast, the Bayes Net in Figure 7 can be factored as

      $$p(E) p(H | E) p(U | E, H) p(D | U, S) p(G | S, E) p (S | U, H)$$

      This factorization may be helpful in a setting where a student's exam score is observed, and a researcher is trying to learn student profiles (their $H$ and $U$) from exam scores.<br> -->

      <h2 id="recap17_5">Beyond Bayes Nets</h2>

      In CS 181, we are only going to focus on Bayesian Networks.  But, there are more kinds of graphical models out there!  We'll briefly introduce two other kinds of graphical models.

      <h4>Undirected Models</h4>

      Undirected models are graphs where the edges between random variables are undirected.  For example, consider graph

      <div id="images">
          <a>
              <img src="{{ site.baseurl }}/images/recap17_7.png" style="width:80%"  alt="undirected"></img>
              <div class="caption">Figure 7</div>
          </a>
      </div>

      The joint distribution of this graph can be factored as

      $$P(A, B, C, D, E) = \frac{1}{z} \phi(C, A, B) \phi(B, D) \phi(B, E)$$

      where $z$ is a normalizing constant and $\phi$ is a function.<br><br>

      Undirected graphical models are very popular in settings such as image segmentation (you can make graphs over pixels in an image).  In practice, they're hard to work with because finding the normalizing constant $z$ that makes $P(A, B, C, D, E)$ a valid probability distribution is hard.

      <h4>Factor Graphs</h4>

      In factor graphs, variables connect into factors, which are denoted by the shaded nodes. Each shaded node corresponds to a $\phi$:

      <div id="images">
          <a>
              <img src="{{ site.baseurl }}/images/recap17_8.png" style="width:80%"  alt="factor"></img>
              <div class="caption">Figure 8.</div>
          </a>
      </div>

      The joint distribution of the factor graph can be written as

      $$p(A, B, C, D, E) = \frac{1}{z} \phi(A,C) \phi(A,B) \phi(B,C) \phi(C,D)$$

      where $z$ is a normalizing constant and $\phi$ is a function.  Normalization here is still tricky.<br><br>

      Each of the $\phi()$ terms was created by examining each of the factor nodes, and including the variables which were connected to each factor.<br><br>

      Factor graphs are more expressive than undirected graphs.  Notice here that we included a factor to add additional term $\phi(B, C)$.  We wouldn't have been able to specify the inclusion of this extra term in our undirected graphical model.
    </div>
</section>
